{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"movie.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "\n",
    "Cleaning text data (removing punctuation, turning to lowercase, removing stop words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nehue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nehue\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "    text = ' '.join(word for word in words if word not in stop_words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grew b 1965 watching loving thunderbirds mates...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>put movie dvd player sat coke chips expectatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though great interest biblical movies bor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im die hard dads army fan nothing ever change ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  grew b 1965 watching loving thunderbirds mates...      0\n",
       "1  put movie dvd player sat coke chips expectatio...      0\n",
       "2  people know particular time past like feel nee...      0\n",
       "3  even though great interest biblical movies bor...      0\n",
       "4  im die hard dads army fan nothing ever change ...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Converting each sample's text into numerical features that can be used as input for an ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Technique: **TF-IDF**\n",
    "**Term frequency - inverse document frecuency**, which highlights the importance of words in a sample in contrast to the collection of all samples, giving higher weights to terms that are frequent within a text sample but rare across the rest of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use TF-IDF vectorizer to convert text data to numerical features\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40000x159207 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4024949 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": make_pipeline(LogisticRegression(max_iter=1000)),\n",
    "    \"Naive Bayes\": make_pipeline(MultinomialNB()),\n",
    "    \"SVM\": make_pipeline(SVC(kernel='linear', probability=True)),\n",
    "    \"Random Forest\": make_pipeline(RandomForestClassifier(n_estimators=100))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nehue\\Documents\\programas_de_python\\machine_learning\\my_projects\\IMDB_movies_sentiment_analysis\\model.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=5'>6</a>\u001b[0m         results\u001b[39m.\u001b[39mappend({\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=6'>7</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m: model_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=7'>8</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mmean(scores[\u001b[39m'\u001b[39m\u001b[39mtest_accuracy\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=10'>11</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mF1 Score\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mmean(scores[\u001b[39m'\u001b[39m\u001b[39mtest_f1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=11'>12</a>\u001b[0m         })\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=13'>14</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(results)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=15'>16</a>\u001b[0m results \u001b[39m=\u001b[39m evaluate_models(models, X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(results)\n",
      "\u001b[1;32mc:\\Users\\nehue\\Documents\\programas_de_python\\machine_learning\\my_projects\\IMDB_movies_sentiment_analysis\\model.ipynb Cell 17'\u001b[0m in \u001b[0;36mevaluate_models\u001b[1;34m(models, X, y)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m models\u001b[39m.\u001b[39mitems():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=4'>5</a>\u001b[0m     scores \u001b[39m=\u001b[39m cross_validate(model, X, y, scoring\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mprecision\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m], cv\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=5'>6</a>\u001b[0m     results\u001b[39m.\u001b[39mappend({\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=6'>7</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m'\u001b[39m: model_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=7'>8</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mAccuracy\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mmean(scores[\u001b[39m'\u001b[39m\u001b[39mtest_accuracy\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=10'>11</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mF1 Score\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mmean(scores[\u001b[39m'\u001b[39m\u001b[39mtest_f1\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=11'>12</a>\u001b[0m     })\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nehue/Documents/programas_de_python/machine_learning/my_projects/IMDB_movies_sentiment_analysis/model.ipynb#ch0000016?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(results)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:267\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=263'>264</a>\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=264'>265</a>\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=265'>266</a>\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=266'>267</a>\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=267'>268</a>\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=268'>269</a>\u001b[0m         clone(estimator),\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=269'>270</a>\u001b[0m         X,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=270'>271</a>\u001b[0m         y,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=271'>272</a>\u001b[0m         scorers,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=272'>273</a>\u001b[0m         train,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=273'>274</a>\u001b[0m         test,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=274'>275</a>\u001b[0m         verbose,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=275'>276</a>\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=276'>277</a>\u001b[0m         fit_params,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=277'>278</a>\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=278'>279</a>\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=279'>280</a>\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=280'>281</a>\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=281'>282</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=282'>283</a>\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=283'>284</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=285'>286</a>\u001b[0m _warn_about_fit_failures(results, error_score)\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=287'>288</a>\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=288'>289</a>\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/sklearn/model_selection/_validation.py?line=289'>290</a>\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=1094'>1095</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=1096'>1097</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=1097'>1098</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=1098'>1099</a>\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=1099'>1100</a>\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=972'>973</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=973'>974</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=974'>975</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=975'>976</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/parallel.py?line=976'>977</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/_parallel_backends.py?line=563'>564</a>\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/_parallel_backends.py?line=564'>565</a>\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/_parallel_backends.py?line=565'>566</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/_parallel_backends.py?line=566'>567</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/_parallel_backends.py?line=567'>568</a>\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/site-packages/joblib/_parallel_backends.py?line=568'>569</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=436'>437</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=437'>438</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=439'>440</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=441'>442</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/concurrent/futures/_base.py?line=442'>443</a>\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/threading.py?line=309'>310</a>\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/threading.py?line=310'>311</a>\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/threading.py?line=311'>312</a>\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/threading.py?line=312'>313</a>\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nehue/AppData/Local/Programs/Python/Python39/lib/threading.py?line=313'>314</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def evaluate_models(models, X, y):\n",
    "    results = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        scores = cross_validate(model, X, y, scoring=['accuracy', 'precision', 'recall', 'f1'], cv=4, n_jobs=-1)\n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': np.mean(scores['test_accuracy']),\n",
    "            'Precision': np.mean(scores['test_precision']),\n",
    "            'Recall': np.mean(scores['test_recall']),\n",
    "            'F1 Score': np.mean(scores['test_f1'])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "results = evaluate_models(models, X_train, y_train)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: **SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the correct hyperparameters with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 64 candidates, totalling 192 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear','rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=1, cv=3, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89      3966\n",
      "           1       0.89      0.91      0.90      4034\n",
      "\n",
      "    accuracy                           0.90      8000\n",
      "   macro avg       0.90      0.90      0.90      8000\n",
      "weighted avg       0.90      0.90      0.90      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with new reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\n",
    "    \"The plot was kind of good I must admit, and loved the action scenes\",\n",
    "    \"The movies was great... For a 2 year old, who doesn't differentiate a car from a plane\",\n",
    "]\n",
    "\n",
    "new_reviews = [preprocess_text(review) for review in new_reviews]\n",
    "\n",
    "X_new = vectorizer.transform(new_reviews)\n",
    "\n",
    "predictions = model.predict(X_new)\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a4565eb6215a326995d9cfd00f1782ebb9ab334d122fb684360bfee2e0fdc62"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
